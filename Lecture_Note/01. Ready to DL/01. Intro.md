# 앞으로 우리가 다뤄볼 내용들

---
- 논문 위주로 다뤄볼 예정입니다


- CNN
- 알파고에 들어가있는 Monte-Carlo Tree search
- Regularization : 딥러닝뿐만 아니라 기계학습 전체에서 매우 중요
	- To avoid Overfitting
- Optimization Methods ( 최적화 방법 )
	- SGD
	- Momentum
	- NAG
	- Adagrad
	- Adadelta
	- Rmsprop  
- Restricted Boltzmann machine
	- RBM으로 pretrain하고, pretrain한 네트워크를 초기값으로 설정해 학습한 뉴럴넷이 성능이 좋다는 결과가 발표
- Denoising Auto-Encoder
	- noise가 있는 데이터가 input으로 들어오면, output으로 noise가 없는 데이터를 출력
- Semantic Segmentation
	- 어떤 이미지가 들어오면, 각 영역별로(픽셀별) 이 픽셀이 뜻하는 것이 무엇인지를 맞추는 것
	- 이미지가 있고 이미지의 각 영역이 무엇을 뜻하는지에 대한 라벨링이 필요
- Weakly-Supervised Localization
	- Semantic Segmentation과 유사한 것을 수행. 이미지가 들어오면 그림 위치에서 각 픽셀들이 어떤 클래스에 속하는지 알 수 있음
	- 이미지와 이미지에 해당하는 클래스 정보만 있으면 됨
- Detection Methods
	- 굉장히 많은 논문들로 이루어져 있음. 2시간 넘게 10편이 넘는 논문을 볼 예정
	- 이미지가 주어지면 그 이미지 안의 물체들의 위치를 찾는 것
	- ex) 강아지의 위치를 네모(바운딩 박스)로 쳐줌
- RNN - LSTM
	- 어떻게 동작하는지, 이 구조를 통해 어떤 것을 할 수 있는지 알아볼 예정
- Visaul Q&A
	- 사진 1장과 사진에 해당하는 질문을 같이 input으로 넣어 문장 + 이미지를 동시에 이용해 정답을 찾는 것
- Super Resolution 
	- 저해상도 이미지가 들어왔을 때, 고해상도 이미지를 찾는 것
- Deep Reinforcement Learning
	- 딥러닝 기법과 고전적 강화학습 기법이 같이 사용되어 기존에 불가능하던 문제를 풀 수 있게 됨
	- ex) 입력을 raw video로 넣고 조이스틱을 어떻게 움직이면 되는지?  
	- 기본적인 강화학습과 DQN을 다뤄볼 예정
- Sequence Generation
	- 새로운 것을 만들어보는 것. 손글씨를 만드는 것을 해볼 예정
- Word Embedding
	- 단어를 어떻게 하면 컴퓨터가 이해하기 쉬운 숫자들로 옮길 수 있는지 알아볼 예정
- Image Captioning
	- Image가 주어지면 Image를 설명하는 문장을 만드는 알고리즘
- Hangul-RNN
	- 한국어를 어떻게 처리할 수 있는지, 복잡도를 해결하는 방법
	- 구운몽을 가지고 학습한 뉴럴넷이 글을 만들 예정
- Residual Network & Analyses
	- Residual 구조를 알아보고, 이런 것들이 왜 잘되는지 알아볼 예정
- Neural Style 
	- 사진을 주면, 그 사진을 고호풍 / 피카소풍으로 바꾸는 알고리즘
	- Texture Synthesis Using CNN, Understanding Deep Image Representations by Inverting Them의 합집합 개념
- Generative Adversarial Networks
	- 현재 지금 연구되고 있는 분야 중 가장 Hot!
	- 기본이 되는 논문부터 시작해서 올해들어 어떻게 발전되고 있는지 알아볼 예정
	- Image Captioning을 반대로 하는 것. 문장을 주고 문장에 해당하는 이미지를 만들어주는 것
	- ex) 모델의 옷을 옷만 추출하는 것   
- Basic Python
- Using MNIST
- Basic Image Handling
- Basic TensorFlow
- Tensor Board
- Logistic Regression
- Multi-Layer Perceptron
- Generating Own Datasets
	- 폴더별로 특정 사진이 모여 있다면, 그 데이터셋을 가지고 학습하는 분류기를 만들어볼 예정
- Word2vec
- Mixture Density Network
	- 뉴럴넷은 고정된 input이면, 고정된 output이 나오는데 그게 아닌 입력이 주어졌을 때, 출력을 가우시단 믹스쳐 모델로 모델링을 하는 것
- Domain Adversarial Network
	- 소스 공간에 이미지가 존재할 경우 input-output을 모두 구하고, 실제로 적용할 타겟 공간에선 input만 주어질 경우 공간에 해당하는 output이 무엇인지 찾는 것
- VAE
- Adversarial Variational Bayes

### Advanced Topic
- One-Shot Learning
	- 뉴럴넷의 가장 큰 단점 : 새로운 데이터를 처리하기 힘들다. 특정 분류기에 새로운 클래스를 추가하고 싶다면 학습 데이터에 추가해 처음부터 다시 학습을 시켜야 함. 
	- 이럴 경우 시간과 컴퓨팅 소스가 많이 들어가는데 주어진 새로운 데이터셋을 어떻게하면 최대한 빨리 고려해 학습할 수 있는지를 알아볼 예정
- Domain Adaptation
	- Domain Adversarial Network
- Metric Learning
	- 2개의 이미지가 존재할 경우 2개의 거리를 나타내는 것. 그 거리를 어떻게하면 잘 학습할 수 있을지 알아볼 예정
- Memory Network
	- 컴퓨터 구조를 따라해 만든 네트워크
	- 메모리에 특정 정보를 넣고, 빼오는 것을 구현해본 것
- Uncertainty in Neural Networks
	- 해당 논문에선 output을 뱉어냄과 동시에 얼마나 잘 예측하고 있는지에 대해 작성되어 있음