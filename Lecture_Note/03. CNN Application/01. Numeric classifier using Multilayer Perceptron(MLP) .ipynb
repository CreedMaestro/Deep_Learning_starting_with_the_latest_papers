{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습] Multilayer Perceptron(MLP)로 숫자 분류기 구현하기\n",
    "- MLP는 Fully Connect layer, Dense layer 등의 이름으로 불림\n",
    "- 기존 cnn에 많이 활용되는 구조\n",
    "- hidden layer가 추가 + activation\n",
    "- linear transformation, affine transform은 아무리 여러번 반복해도 affine이라 중간 중간에 non-lineard를 줘야 훨씬 더 복잡한 함수로 모델링할 수 있습니다\n",
    "- 각 레이어의 output이 나오면 activation function을 통과함 (sigmoid, tanh, relu)\n",
    "- 마지막 output이 나오면 softmax를 취해서 cross entropy에 넣으면 logistic regression\n",
    "- 우리의 코드에선 softmax를 취하지 않을겁니다! \n",
    "- softmax를 취하기 전의 값을 logit이라 부르고, 이것을 입력으로 받는 텐서플로우 함수가 있는데 그것을 활용해보겠습니다\n",
    "\n",
    "### Logistic regression과 Multi layer perceptron의 차이\n",
    "- Depth!!!\n",
    "\n",
    "\n",
    "- 아래 코드는 모델, Cost 정의 -> 초기화 -> 실행 순으로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T13:20:21.720636Z",
     "start_time": "2017-11-08T13:20:09.786947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PACKAGES LOADED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline  \n",
    "print (\"PACKAGES LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T13:21:19.504537Z",
     "start_time": "2017-11-08T13:21:18.872634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T13:27:20.365509Z",
     "start_time": "2017-11-08T13:27:20.294527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK READY\n"
     ]
    }
   ],
   "source": [
    "n_input    = 784 \n",
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 128 \n",
    "n_hidden_3 = 64\n",
    "n_classes  = 10  \n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "    \n",
    "# weight와 bias가 여러개 있고, dict으로 들어가있음\n",
    "stddev = 0.1\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=stddev)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=stddev)),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3], stddev=stddev)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_3, n_classes], stddev=stddev))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "print (\"NETWORK READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T13:32:13.879105Z",
     "start_time": "2017-11-08T13:32:13.593867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTIONS READY\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "def multilayer_preceptron(_X, _weights, _biases):\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1']))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2']))\n",
    "    layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, _weights['h3']), _biases['b3']))\n",
    "    return (tf.matmul(layer_3, _weights['out']) + _biases['out'])\n",
    "                                                               \n",
    "# 위 함수는 softmax가 없습니다!\n",
    "# softmax_cross_entropy_with_logits을 활용할 예정이라 그렇습니다!\n",
    "\n",
    "# PREDICTION\n",
    "pred = multilayer_preceptron(x, weights, biases)\n",
    "\n",
    "# LOSS AND OPTIMIZER\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)) \n",
    "# 들어가는 것은 logits이지 확률이 아님!\n",
    "optm = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)\n",
    "corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accr= tf.reduce_mean(tf.cast(corr,\"float\"))\n",
    "\n",
    "# INITIALIZER\n",
    "init = tf.global_variables_initializer()\n",
    "print (\"FUNCTIONS READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-08T13:33:27.002995Z",
     "start_time": "2017-11-08T13:32:29.965103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/020 cost: 0.123953741\n",
      "TRAIN ACCURACY: 0.970\n",
      "TEST ACCURACY: 0.964\n",
      "Epoch: 007/020 cost: 0.048301718\n",
      "TRAIN ACCURACY: 0.980\n",
      "TEST ACCURACY: 0.975\n",
      "Epoch: 011/020 cost: 0.019357661\n",
      "TRAIN ACCURACY: 0.990\n",
      "TEST ACCURACY: 0.980\n",
      "Epoch: 015/020 cost: 0.007246731\n",
      "TRAIN ACCURACY: 1.000\n",
      "TEST ACCURACY: 0.980\n",
      "Epoch: 019/020 cost: 0.003026320\n",
      "TRAIN ACCURACY: 0.990\n",
      "TEST ACCURACY: 0.980\n",
      "OPTIMIZATION FINISHED\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "training_epochs = 20\n",
    "batch_size      = 100\n",
    "display_step    = 4\n",
    "# LAUNCH THE GRAPH\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# OPTIMIZE\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    # ITERATION\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        sess.run(optm, feed_dict=feeds)\n",
    "        avg_cost += sess.run(cost, feed_dict=feeds)\n",
    "    avg_cost = avg_cost / total_batch\n",
    "    # DISPLAY\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f\" % (epoch, training_epochs, avg_cost))\n",
    "        feeds = {x: batch_xs, y: batch_ys}\n",
    "        train_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\"TRAIN ACCURACY: %.3f\" % (train_acc))\n",
    "        feeds = {x: mnist.test.images, y: mnist.test.labels}\n",
    "        test_acc = sess.run(accr, feed_dict=feeds)\n",
    "        print (\"TEST ACCURACY: %.3f\" % (test_acc))\n",
    "print (\"OPTIMIZATION FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
